<img src="https://pic4.zhimg.com/8d02ad62036808353f181a4996aa52e6_1440w.jpg?source=172ae18b" alt="图片替换文本" width="400" height="400" align="middle"> </img>

## 认知科学、神经科学、和认知神经科学



1. 认知科学的重点是研究人类的心智和认知过程。
2. 神经科学的重点是研究人类神经系统，人类的中枢神经系统。



<img src="https://originalstatic.aminer.cn/misc/shaozhou/AI-history-new.jpg" width="600">

# D认知系统

需要思考一个问题是，能否用一个抽象模型将多个策略融合起来？

1、事件目标转移的回溯机制。

2、具体事件是否发生。

3、认知带程度的事件。

4、带程度事件的规律如何生成。

5、带程度事件和离散事件的信息转换。

6、因果链条的桥接的基础思维机制和反应模式。

7、抽象策略。 

8、统计认知

​		

-----

#### 认知系统三大任务的联系

- 获取知识是三类任务的核心。

- 目标依赖因果类型的知识进行转移分解。

- 而判断具体事件是否发生需要因果层次的知识。

获取知识具有自我支持的特点，即获取新知识大部分时候也需要即存的知识。

​		**认知模型的作用：**在主动阅读时，认知模型的作用：主动搜索、计算、找到被动阅读无法获得的信息。信息如何过滤？思考到一个问题时，关注度就转移到与其相关的事件或知识中去，从记忆库或是common sense中搜寻能匹配信息。这些信息能被认知模型统辖，从而能有效的运用到认知演绎和大段文字组织的反应模式中。会决定哪些知识会被有效运用？

​		钱总的意识流结构具有的特点：能很高效的将一个句子进行解析，而且结构完整，表述的信息也完整，可以将事件或对事件的描述全都指向一个事件目标或一个具体对象。这样在进行抽象时，也能比较全面抽取相应的信息。

#### 认知系统的核心逻辑：

​		“凡是定义在母类的知识可以被子类继承，凡是定义在母类反应模式可以被子类继承，凡是定义在母类的语法映射可以被子类继承，凡是定义在母类的情绪反应可以被子类继承”

​		概括一下就是面向对象的语言，子类可以被母类所继承。

​		定义一条在母类层事件类间的知识，ID0(原因:IDA,结果:IDB)，IDA和IDB分别是母类层的事件类。那么对于一个具体事件，可以匹配一个知识层的母类事件，从而获得一个子类事件。而可以通过母类层的知识生成(因果层的事件)得到相应的结果。

​		问题就是如何继承母类事件所在的知识，以及母类的知识如何通过子类层的相关关系抽象生成？？？？

----



## Chapter 1 抽象、归纳、演绎(未完待续)

### 统辖关系、统辖检测、统辖搜索

**统辖关系：**就是找到具体事件的母类事件，实现让子类继承母类所具有知识。

**统辖检测：**检测 A是不是B的统辖母类。

**统辖搜索：**有显性的统辖关系和隐性的统辖关系。挖掘潜在的统辖关系，将潜在的统辖关系转化为显在的统辖关系。（类似于知识推理的过程）

<img src="C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20201130113214606.png" align="middle" width="400">

对于一个具体事件，经过自然语言正转录过程会生成一个**事件域**，对这个事件域中的所有事件进行**统辖检测**，找到统辖它的母类就是**统辖搜索**。

#### **统辖搜索的具体流程：**

对较为具体层的事件IDA'，在记忆中查找存在的IDA'的统辖结构。

- 显在的统辖关系
  1. 把IDA‘展开；
  2. 在IDA’同结构类型的节点中进行搜索；
  3. 先对IDA‘第一个位格元素查找显在的统辖结构，搜索所有第一个位格链接元素母类的{IDAj}的集合。
  4. 对其他位格做同样的操作得到很多个{IDNj}，然后取交集。
- 对于潜在的统辖结构，我们需要对位格上的元素展开，把潜在的统辖结构给标记出来。

### 演绎

演绎的过程可以认为是知识推理的过程。意思就是我根据表层意识建立了一个关系的，以及我潜在的知道一个知识，那么我就可以推理出相应的其他知识。

但是演绎和推理会有很多路线，反应路线的产生是反应模式产生的。而反应路线的选择是情绪系统决定的，情绪系统决定了反应模式的权重。

匹配因果的统辖关系，形成知识。

- 预测演绎

- 归因演绎

#### 演绎反馈

抽象和归纳始终具有猜想的属性，为了提高知识的可行度，需要对知识进行修正，这称为演绎反馈。

> 拓展：样本巧合、特定的背景条件、样本信息缺失等因素

#### 演绎的过程

（peter穿着红色的衣服，从属于’红色的物体‘）

因此在运算过程中形成了子类对母类的约束映射。

用约束映射中子类的元素替代母类中的对应元素写入到知识关联的另一个事件类IDB中。

1. 起点输入为子类事件IDA'
2. 在存储知识的记忆空间中，把组织知识的事件作为统辖搜索的母类事件域。进行统辖搜索找到统辖IDA’的母类IDA。并建立子类和母类间元素建立约束映射。
3. 在出指出知识的记忆空间中寻找IDA所在的知识ID0。

<img src="C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20201221170557719.png" align="middle" width="400">

### 抽象

​		钱总认为抽象出来的知识总是一种猜想。而且一条表象层的具体知识能够同时抽象出多条不同的抽象的知识，而每一条抽象策略的强度是不一样的。

> 我的理解：
>
> - 建立事件之间的关系
>
> - 自身信息处理逻辑
>
> 一条信息可以抽象出多条关系 ----> 知识的强度筛选（召回和排序）
>
> 事物之间有些强相关逻辑和弱相关联系。
>
> **意识流实际上就是提取事情发展规律变化的梯度。**
>
> 事件会影响决策。
>
> ##### 研究目标（mpj的意图）
>
> 分清一些内容？
>
> 一些是专业型的场景，这是一个强的业务范围。
>
> 一种是普通的泛化的base的功能，实际上就是能在任何业务场景中都适用的解决方法。



### 归纳

钱总认为具体案例中会出现组合爆炸的问题，而归纳的核心就是，将多个具体层面信息对应位置的最小母类生成一条知识。

#### 归纳和抽象的配合

将不精准的知识精准化。抽象过程获得的知识不足够精确就会导致“抽象泛化”。

由一个具体事件对象抽象出多个猜想，然后对多个猜想做归纳（最小母类）产生。



### 最小母类原则

定义：如果子类在继承知识时不同母类之间出现相互矛盾的知识，这时优先继承较小母类知识。

```markdown
其实就是决策树原理，或者就是特征分类的过程。
因为有多棵树，不同的树根据不同的输入特征，可以获得一个判别结果。
案例：牛攻击人。给牛和人不断添加特征，判断牛是否攻击人。这就是一个事件的决策过程。也是一个动作的决策过程。
矛盾知识，实际上就是根据具有不同特征决策树获得的抽象知识。
#矛盾知识的解决？
会有一些不同程度的知识：大概率知识、小概率知识、完全不可能知识。
由于统辖关系的建立，知识点之间存在抽象和归纳。
```

------





## Chapter2 事件目标的转移

### 基本概念

**事件目标：**人类对事件的发生与不发生，即存事件的终止和维持有自己的意志和目标。

**触发事件：**发生即产生效果事件

**状态：**存续产生效果的事件

**事件转移目标的作用：**实现能力不可及到能力可及的过程。

​		广义事件之间的相互创造、终止、维持和阻止发生。人类在产生动机之后，比如治愈癌症、避免心血管疾病是怎样的反应模式驱动最终获得这个目标的解决方案的。如果一个事件目标不可直接实现，会考虑利用知识进行分解转移，把认知动机转移到其他事件目标。

- **所以有哪些知识或认知目标可以转移？**

创造关系、维持关系、终止关系。

两个关联的事件间可能存在大量的因果链条，而一个事件的发生往往受到很多不同事件和状态的影响。我们观察到的可能只是贡献关系。 

> 借用隐马尔可夫的猜想，当前状态只与上一个状态有关，而与上一个的上一个状态无关。
>

而因果链条能获得很多贡献关系或影响关系。



### 事件目标的转移规则

#### 目标转移的条件：能力不可及

​		事件目标发生转移的前提条件是当前事件不可执行（能力不可及），去寻找需要的哪些必要条件和充分条件，如果条件的必要性很高，就**一定**要考虑这个条件是否能满足要求。~~（这个条件满足了要求就要看这个条件的充分性，如果这个条件的充分性很高，就不需要考虑其他的条件）？？？？。(如果这个条件的充分性低，所以会优先考虑相关的所有必要的条件以及这些条件的充分性，使得必要条件都有（不论充分性多高），解决那些不满足要求的必要条件。)~~如果所有的条件都满足必要性，就要选择充分性的事件去执行，如果事件的充分性不足，就要执行多条充分性事件（一般就会执行一个高充分性的事件，来解决必要条件）。

​		以上就包含了“事件目标能力可及”以及“必要性和充分性的说明”。如果当高充分事件中也还存在必要条件的缺失，就要进一步的对目标事件进行分解。**对于所有的状态，都要转移到实现（终止或维持）这个状态的（创造|阻止）事件当中去。**

​		**总的来说，就是如果存在不满足要求的必要条件（能力不可及），就要向解决必要条件的充分事件（能力可及事件）出发----目标转移，并解决所有必要条件。**

#### 状态和事件

- **状态是可以被创造维持和终止的。但事件只能被创造和阻止。**

  “状态”可以认为是现在进行时的事件，“事件”被认为是一般现在时。比如吃糖会导致肥胖，这是个通常性、规律性、习惯性、真理性的动作或状态。比如益生菌生长是一个现在进行时的事件，表示正在发生。

​		因此，对一个正在发生的事件，我们需要找到维持这个状态或创造这个状态的事件。比如持续给营养物质让益生菌生长。持续给营养物质是个状态，因此是个维持事件。但这个状态没法被直接执行，因此需要继续目标转移，找到“创造，持续给营养物质”的事件，也即给“培养皿中添加琼脂等”，这是一个创造事件。

以上要说明的问题是，**所有状态相关的事件要转移到可以被执行的事件**，这样就将所有的状态和事件统一起来了。

#### 目标转移路线

1. 意图识别为，终止状态A：会搜索知识（事件B（状态），终止状态，状态A），从而将事件目标转移到“创造-事件B”。也会搜索知识（事件B（状态），维持状态，事件A（状态））从而将事件转移到“终止状态（B）”。也还会搜索知识（事件B（状态），创造关系，状态A），从而将事件转移到“阻止事件B发生”

2. 意图识别为，创造事件A（状态）：会搜索知识（事件B（状态），创造关系，事件A（状态））从而将事件目标转移到"创造事件B|维持状态B"。也会搜索知识（事件B（状态），阻止发生关系，事件A（状态）），把目标转移到“终止状态B”、“阻止发生事件B”。

3. 意图识别为，维持状态A：会搜索知识（状态B，维持关系，状态A），把目标转移到“维持状态B”。除此之外还会搜索知识（事件B（状态）,终止关系，状态A）），把目标转移到“终止状态B”、阻止发生事件B（状态）。

4. 意图识别为，阻止发生事件A（状态）：会搜索知识（ 事件B（状态），阻止发生关系，事件A（状态）），把目标转移“创造事件B（状态B）”或“维持（状态B）”。（事件B（状态B），创造关系，事件A（状态A））把目标转移到终止状态B、阻止发生事件B（状态）。

   

![image-20201124131847781](C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20201124131847781.png)



##### 终止状态A的目标转移

<img src="C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20201204142844031.png" align="middle" width="500">

##### 创造事件A（状态）的目标转移

<img src="C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20201203090822089.png" align="middle" width="500">

##### 维持状态A的目标转移

<img src="C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20201203091506499.png" align="middle" width="500">

##### 阻止发生事件A（状态）的目标转移

<img src="C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20201203090856618.png" align="middle" width="500">

​		现在将四个转移路线，特别是状态也是一种事件，这样全部都转换成**对象（事件）导致对象（事件）**的事件了（这只是M语言结构，暂时不需要考虑）。

​		阻止发生和终止状态都会有四个走向，而创造和维持只有三个走向。而每一个状态（发生/不发生/维持/终止），都会有两种路线可以走，分别为直接路线和间接路线，在做判断时会优先思考直接方法的事件B是否存在，如果存在就找到事件B的事件C是否存在，并执行这个事件C，从而实现事件B。如果没有找到直接事件，就会找间接事件，触发逻辑是相同的。在图中，橙色到黄色的过程，表示为需要执行的动作，也即转移到的目标事件。



#### 能力是否可及

​		事件目标转移的核心问题是**“能力是否可及”**，如何判断智能体能力是否可及就成为一个非常重要的主题。这涉及智能体对于自己能力的认知，也包含对其他事物能力认知的水平了，或者叫做“自我认知”。比如，一个1岁的小孩，想要触碰高一米的门把手。当智能体解析目标时，尝试碰触到门把手，但是够不着。智能体就开始思考，“如何才能够着”，目标转移到，“碰的更高”，就想到搬凳子来增加触及的高度。因此，智能体就找到了解决身高不够时的办法。但这里有个问题，就是尝试触碰门把手，怎么就产生了身高不够这样的问题呢？实际上，智能体在尝试多次以后，就会触发一些机制，找到能力可及的人来帮助自己解决或学会这个问题。整体实际上是反应模式的触发机制。

#### 目标分解的作用

​		目标分解能帮助我们认识完成一个目标需要经历怎么样的过程。实际上，这是一个演绎过程，而在演绎的过程中会产生非常多的路径。在这些路径中，当然也包含了最优的路径，我们通过不同的代价函数（实行路径的消费），来客观的评价路径最优性。这意味着，不同路径有不同的特点，比如有些路径转换少，有些路径长，有些用时短，有些资费消耗少等等。根据不同的需求选择合适的路径，也许是目标分解也需要考虑的重要问题。举个具体例子来说明，比如我想出国留学，我可以报名新东方学习，也可以自己学，也可以请教学长学姐老师等等，可以想象自己闷头苦学无疑是比较省钱的方法，但相应的会面临很多未知的问题，而报名新东方会让你申请出国方便很多，但代价是昂贵的学费，请教学长学姐是个折中的方法，所谓得道多助。针对不同的人，其关心的点都不一样，因此路径选择还是因人而异的。

​		另外，此处尚且没有考虑询问的重要性。这在目标分解中无疑是非常重要的锦囊妙计，绝大多数无法被解决的问题都可以通过询问来解决。比如，我想坐公交到西湖区玩。在拥有百度地图的前提下，我可以通过app实现目标，而不需要依赖认知推理来实现，这无疑徒增烦恼。但是，如果在记忆中已经出现了合适路线，那就没推理什么事了，走就可以了。以上可以得到一个结论是，建立在抽象层或是知识层的推理层是相对高效的，这意味着我们需要限制目标分解的层级，无限制的分解将会导致问题的复杂性。在这里，我们认为可以让那些过于复杂的目标分解，总结到询问来解决。简单来说就是计算子目标树的复杂度，剪枝并用询问替换根节点。类比人类大脑的思维过程就是避免了思想过于发散。



#### 能力可及程度的计算

​		能力是否可及涉及的问题是比较复杂的，这是事件目标是否要发生转移的判别标准。这里认为一个事件的能力可及程度和这个事件的上游事件的能力可及程度，和上游事件与目标事件的充分性有关。这里充分性的作用是对路径的筛选，只有充分性达到某个值，才能进入充分性的计算。当调节对充分性阈值的要求，我们就能解锁更多路径。如果上游事件的能力可及性与充分性的计算结果上尚且还不能满足对能力可及程度的需求的时候，就要尝试对上游事件进行目标分解来提高上游事件的能力可及性。这样，最终都能总结到那些能力可及的事件上去，也保证了在目标分解树上的每一个节点都有相应的能力可及值。当一系列的树构建完成，且达到了当前能力可及的要求的时候，就要从当前的构建的子树中挑选那些，容易实现的路径，即那些树的复杂度低的事件（树的节点树比较少，树的深度比较低，树的分支比较少等。）



#### 其他问题

1. 能力是否可及怎么判断？
2. 目标分解的终点。树复杂度的计算。



### Chapter3 具体事件是否发生

​		**作用：**从因果层的知识去推演事件的原因和事件导致的结果，从而将判断目标事件是否发生转移到判断因果链条相关的其他事件是否发生或状态是否存在上面，指导找到感知可及的事件。

#### 感知可及

感知可及：靠感官可识别的事件，包括直接感知和间接感知。

- 直接感知：通过感官或“感知工具”的对事件的感知。

- 间接感知：利用事件所在的因果链条中的相关事件间接的判断它是否发生。为了判断一个直接感知不可及目标是否发生，会利用因果关系把观测目标转移到直接感知可及的事件上。


间接感知的两个方向：

- 向上考察导致这个事件的上游的因果链条，可以直接感知的原因。
- 考虑这个事件向后延伸的因果链条。

总的来说：一个事件的发生或不发生，状态的存在或不存在，如果是可以“直接感知”或是“间接感知”的，我们都称之为“感知可及” 的。



#### 充分和必要性

假设A是条件，B是结论，设C，D分别为A，B所描述对象的集合，则有下列定义和推论：

1、A推出B，B推出A，则为充要条件。($C=D$)

2、A不一定推出B，B一定可以推出A，则为必要不充分条件。($C\supsetneqq D$)

3、A推出B，B又不一定推出A，则为充分不必要条件。($C\varsubsetneqq D$)

4、A不一定推出B，B又不一定推出A，则为不充分不必要条件。($C \nsubseteq D,D\nsubseteq C$)



#### 判断具体事件是否发生规则

​		判断事件是否发生的前提是因为当前条件下无法直接感知当前事件是否发生**（感知不可及）**，而需要发生目标转移，并从目标事件的原因事件和导致的结果事件中寻找可感知事件，判断这些事件是否发生来对当前事件是否发生形成认知。<font color=red>总的来说，就是利用因果关系把感知不可及事件转移到感知可及事件上去。</font>

##### 从事件的结果判断

​		如果目标事件导致的结果是可以感知的（感知可及），并把可以直接感知的事件叫做“表象事件”，我们就从表象事件来判断目标事件是否发生。这里目标事件和表象事件的关系可以分为两种，其满足充分与必要性的推理：

（1）目标事件是导致表象事件的单一原因，也就是一个必要不充分原因。这意味着表象事件发生，目标事件一定发生；目标事件发生了，表象事件不一定发生。

（2）目标事件是表象事件的一个充分不必要原因。这意味着表象事件发生，目标事件不一定发生；目标事件发生了，表现事件一定发生。

案例1：

```python
	问诊过程。判断对方是否有某个疾病。我们可以通过可感知的症状来确认可能的疾病，这是后延因果链条的知识。当症状出现了，认为这个疾病是有可能的。但同时，还要排除那些可能导致这个症状的疾病。就要利用判断一个事件是否发生，如果其他疾病不存在，那么目标疾病的可能性就很高，相反其他疾病存在，就要考虑其他症状。由此就可以比较精确和高效的找到对应的疾病。
```

从事件结果判断目标事件是否发生的流程：

1、搜索目标事件所在的后延因果链条，也就是考察目标事件如果发生会发生什么。

2、优先选择那些具有强充分性或强必要性的事件，因为这些事件能直接形成对事件是否发生的肯定或否定。

3、如果理想的情形不成立，就需要继续考察这些表象事件是否可能由其他原因事件导致。

4、如果可能由其他候候选事件导致，就回到起始状态：判断这些事件是否发生。最好的情况就是能够排除其他可能导致表象的事件。

5、还有一种方式，考察竞争的几个原因哪个能够形成对需解释表象京尽可能完整的解释覆盖。

##### 从事件的原因判断

有时候从事件的结果判断是否发生未必具有足够的条件，比如：

1、感知可及的结果事件还没有发生。

2、事件的结果事件是感知可及的，但是不是直接感知可及的，而间接感知因为各种原因缺乏条件。

3、事件的结果事件虽然是感知可及的，但是因为某些原因无法向知晓它的个体询问。

​		因此，如果无法从事件的结果表象判断事件是否发生，就会从事件发生的原因是否发生来判断目标是否发生。但是知晓事件发生的原因未必能确定目标事件发生了，原因事件通常是对结果事件有一定的贡献作用。因此原因判断在特定条件下才会有实践价值，而且搜索的原因事件也是感知可及的。有些事件的原因是强充分性的，比如我没有被狗咬，因此我很大程度上不会得狂犬病；我如果被狗咬了，我就有很大的可能得狂犬病；水煮沸了，细菌一定会死。

##### 从原因与结果判断

​		总的来说，对于一个无法直接感知的目标事件可以分别从事件的原因（充分性）和导致的结果（必要性）来判断目标事件发生的可能性。高必要的结果事件能直接说明目标事件发生了，高充分的原因事件也能直接导致目标事件的发生。但这里需要涉及一个问题就是通过原因和结果的充分必要程度如何来判断事件发生的可能性，因为原因事件和结果事件会有很多，也不一定能找到具有强说明性的高充分或高必要事件。这时，就要从表象的多个较低的充分或必要事件出发，来综合评价。

- [x] <font color=red>充分性和必要性与事件发生概率的转换机制需要仔细研究。</font>



>  案例2：
>
>  > 1被狗咬的人可能会得狂犬病。（概率：0.5）
>  >  2被得狂犬病的咬的人一定会得狂犬病。（概率：0.95）
>
>  ​	 如果先得知信息1，是从狗的知识中去匹配概率。如果有人告诉你这条狗有狂犬病，那么相应的要使得狂犬病的几率增加，实际上匹配的对象变为了“得狂犬病的狗”，那么如果后面发现了他的特征比如这是一只阿拉斯加，很大，今年4岁，大概40kg重，白色的，绝育过，打过疫苗等等信息。那么我们需要从哪一条知识继承知识呢？这里为了减轻搜索知识的过程，我们的任务其实变成一个有导向性的工作。已知任务是“判断我被狗咬了是否得了狂犬病？”，那么就已经绑定了因果树，即要从意识流中搜索去匹配满足因果树的条件。其基本过程和意味树的构建很类似。
>
>  ​	 从结果事件，即那些可感知的症状，恐水、怕风、[咽肌痉挛](https://baike.baidu.com/item/咽肌痉挛/10455984)、进行性[瘫痪](https://baike.baidu.com/item/瘫痪/9947450)来进行判断，如果存在那些症状，说明很有可能得了狂犬病。否则可以从间接的可感知事件如医学检测等判断。
>
>  ​	 从原因事件，即判定这只狗是否携带狂犬病病毒。病犬表现为狂暴不安和意识紊乱。病初主要表现为精神沉郁，举动反常，如不听呼唤，喜藏暗处，出现异嗜，好食碎石、木块、泥土等物，病犬常以舌舔咬伤处。不久，即狂暴不安，攻击人畜，常无目的地奔走。外观病犬逐渐消瘦，下颌下垂，尾下垂并夹于两后肢之间。声音嘶哑，流涎增多，吞咽困难。后期，病犬出现麻痹症状，行走困难，最后终因全身衰竭和呼吸麻痹而死。具有上述典型症状的病例，结合有被咬伤的病史，可作出初步诊断。
>
>  > 这一段是否可以使用神经网络训练的方式来帮助我们认识狗是否有狂犬病。？？？待定吧。
>  >
>
>  ​	 由于对症状的描述越来越多，特征与结论之间的关系变得越来越不好分辨。而且症状到疾病的概率问题也无法判断。这意味着，我们不能仅从感知到的信息判断狗得狂犬病的概率。只能通过医学的检测手段，确实的决定这条狗具有狂犬病。因此， 这一切与狂犬病相关的特征都只能增加对这是“得狂犬病的狗”的猜想。从可能到非常可能，而统计得到多大的概率是不切实地的。因此，我们在描述此类事件的时候，尽可能的只用程度词来表述。比如{“一定”，“非常可能”，“可能”，“不太可能”，“不可能”}分别来描述发生的可能性。当不能获得“一定”的概率时，随着判断条件的增加，我们也仅用“非常可能来描述”。而这种程度的词在转换成概率参加运算时，我们需要进行一定的转换。“一定”的概率为100%-85%，“非常可能的概率”为85%-65%，“可能”的概率在65%-45%，”不太可能“的概率在45%~15%之间，“不可能的概率”为15%-0%之间。有些时候这些数值则不用来参与运算。比如，刚开始得知我被狗咬了，那么我得狂犬病的概率应该是“可能”，当我判断这只狗是否得狂犬病的时候也只能得到可能，但一旦我知道这只狗有一些明显狂犬病的症状时，我的可能性就是“非常可能”，得到更多的症状并不能增加这种可能性。只有当医生告诉我，这只狗有狂犬病时，我才能有更大的可能性认为，我一定被一只得了狂犬病的狗咬了。但如果在医生告诉我之前，有人告诉我这只狗打过狂犬病疫苗，且没有被咬伤的经历时。我得狂犬病得概率就下降到，不太可能。除非医生告诉我，这狗确实有病。
>
>  ​	 **这意味着存在高充分性事件的时候，高充分事件对概率的判断有着较为决定性的作用。**因此，在考虑这些事件的时候，我们还要着重的考虑事件的充分性，才能比较综合的对这个事件发生的概率有较精确的描述。
>
>  > 一阶段：我们认为这样的推理树的构建也是完备的。
>  >
>  > 对比了BP的程度或概率的计算，我发现，由于人对事物的理解是一种离散的状态，当然对于机器或是高智商的人，可能是更加准确的数值。但是对于自然的人而言，对事件是否发生的概率，划分为多个级别已经具有很强的适用性。而使用BP的计算本身是对数据有较高的要求的，有些需要多个同类事件才能满足要求，也就是说，一个结论的获得会依赖其他多个事件，这对于计算而言是存在很大弊端的。所以，我们始终认为事件之间的关系是相对独立的，而事件之间可以用其他事件构建网络，最后达到一个目标事件。如果可以，便可建立开始到目标的路线，其概率计算是可以借助中间事件的相应值，也可以不依赖，但这种不依赖是隐性的。因为一定再次建立了开始到目标的路线，其概率问题就有了。**可以认为，建立路线的过程，实际上就是用路线来表示，一个目标事件。**



是否发生模块的原理图和案例如下所示：

**是否发生模块一般流程：**

![是否发生模块一般流程](C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20210113162505723.png)

**是否发生模块demo**：

![是否发生demo](C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20210113162537002.png)

​		这是两条不一样的路线，两条路线一般都走的通，但是一般向下推知，在没有条件的情况下，辅助向上推知。对一个**不可直接感知的待判断事件**进行因果追溯，分别从其原因事件和结果事件推知。一：结果事件的判别结构是先将判断问题转换成搜索问题，也就是，如果我得了狂犬病，会发生什么？然后从知识中搜索到人得狂犬病得结果事件（知识），与具体事件我得狂犬病的结果匹配，存在，就继承知识的概率，进入计算，模块得到得狂犬病得概率。二：寻找高充分性的原因事件，如果出现新的实体，就要判断当前实体是否存在，如果存在，判断是否匹配该实体。如果这个待判断事件也是不可直接感知的，就再次触发是否发生模块。得到原因事件的概率，结合一个统计概率，判断目标事件的概率。

![image-20210126151512902](C:\Users\莫品军\Desktop\image-20210126151512902.png)

对于单个事件，只继承规律事件，如果不是规律事件，没有发生概率，则不继承。

**模板限制**：认为描述本体特征的原因是需要转换的。如“因为我有恐水症，所以说明我得了狂犬病”，“我被得狂犬病得狗咬了，我得狂犬病。”，“我得狂犬病了，所以我有恐水症”，对于这种现象，不需要对模板进行限制。因为，我得狂犬病和我得恐水症其实都是不可直接感知，最终都要转换到那些可以感知的事件上，比如，我不能喝水等事件上。但是“因为我有恐水症，所以说明我得了狂犬病”，“因为我得狂犬病了，所以我有恐水症”。这样的事件怎么转换呢？两个事件建立联系就好。




#### 时点规律和时序规律

​		如果事件之间存在时间序列上的变化，我们就可以用时间序列的关系表达事件之间的关系。也就是说可以根据一个时间序列和当前的事件来描述（推知）其他的事件。一个智能化的场景使用：妻子知道我开车从公司回家大概多久，就能根据我的出发时间判断我到家的时间，从而适时地准备好晚餐。

​		另外，相较于空间，时间上事件之间并不具有强烈的互斥性，这是因为时间的连续性。因此多个事件在时间上可以发生重叠。为了精准的定位事件的时间状态，对于持续事件通常需要至少两个参数描述。一：开始时间，持续时间，根据持续时间我们就可以推断结束时间；二，也可以用，开始时间+结束时间来描述，根据时间差来推断持续时间，比如妈妈正在做饭，{对象：妈妈，行为：做饭，开始时间："17:30"，结束时间：“17:30+”}。两个结构是等效的，可以随意使用。另外，对于瞬时发生的事件，只用一个开始时间描述，比如：猎人开枪了，{对象：猎人，行为：开枪，开始时间：刚刚}。但是为了计算的完整性，通常会把缺失的位格信息补全，至少是具有开始时间和结束时间的。

​		因此，在获得了大多数事件时间上的完整信息后，就能获得时间轴，或者绘制得到甘特图，根据时间轴上是否有交集从而判断事件是否发生。根据时间上的分布，我们也就可以从时间上判断一个事件在时间事件序列上的可能性。

> 注：甘特图是用于项目规划使用的，当前场景更复杂，不适用？？。

##### 时间规律信息是如何描述的？

​		单个事件用发生概率描述，两个事件的关系用充分性和必要性描述。

​		一个有事件规律通常在程度上和时间上是有所表达的，因此我们认为在表述上是具有相对固定结构的，如下表所示。比如“peter一般7点起床”，我们认为这是个比较合格的**事件规律**描述；而“peter在7点起床”，我们认为这不是一个事件规律，只能认为是个**“一般事件”**，因此是不具备事件规律的M语言结构的，在位格上缺乏“发生概率”。同样的，“植物总是在春天发芽”是个事件规律，而“植物在春天发芽”是个“独立事件”。这样的独立事件在理解上都会产生很多歧义的。这是因为语义理解的不完整性，可以想象在我们理解“植物在春天发芽”这句话的时候，大脑是产生了很多模糊理解（语义补充）。比如产生了“植物在春天**都**发芽了”（着重点在表达客观现象的普遍性，客观规律），“**这个**植物在春天发芽了”（可能为着重突出了某个植物），“植物**会在**春天发芽”（着重点在表达植物的能动性）。总的来说就是大脑会根据关注信息的不同，脑补产生不同的理解。So, it's quite complex. 大脑这种模糊匹配和脑补的特点，也使得思想不那么局限，“脑洞大开”，这也是人类创造力的来源之一。

​		<font color=blue>**那么如何区分脑补的信息呢？**</font>值得肯定的是描述规律的事件，其M语言位格都是带有”发生概率“的，我们认为这样的事件是在概率计算时会匹配到的。而有些信息只是在认知处理过程中产生的。比如”油菜花在春天发芽了“，这个时候”植物在春天发芽“这样的概念只是其抽象结构。然后根据位格信息从知识库中去匹配知识（规律），并从知识那里继承概率。

​		没有概率的事件是怎么回事呢？其实就是一般事件。一般事件按照需求和规律事件进行对比。比如，”peter在7点起床了“，但是知识是”peter一般7点还在睡觉“，因此一般事件和规律事件发生了冲突，也许就询问为什么了:question:。如果知识是“peter一般7点起床”，那么就继承事件发生的概率，方便后续事件之间的相互计算。

|          事件          |                          M语言结构                           |
| :--------------------: | :----------------------------------------------------------: |
|    peter一般7点起床    |     {对象：peter，行为：起床，时间：7点，发生概率：一般}     |
|   植物总是在春天发芽   |     {对象：植物，行为：发芽，时间：春天，发生概率：总是}     |
| 小香槟周日一般会去公园 | {对象：小香槟，行为：去，行为对象：公园，时间：周日，发生概率：一般} |



#### 时间的处理

**时间的类别：**

- 一般时间：世纪，年，月，周，日，时，分，秒，季节（季度），时辰，上下午，上中下旬。
- 状态时间：一会儿，一下，瞬间，马上，立刻，很快，飞快，霎那，转眼间，眨眼间，突然，一刹那，片刻，须臾，短暂，眨眼间，大约、左右、前后、可能、大致。（获得了一个词表）
- 阶段时间：小时候，幼年，青年，青春期，中年，壮年，老年，成长期，成熟期，衰老期，繁殖期。
- 量词+时间：半个月，一年，一上午，几个月。
- 成语：光阴似箭，岁月如梭，年复一年，日积月累，日落西山，白驹过隙，转瞬即逝，迅雷不及掩耳之势，分秒必争、似水流年、争分夺秒、日日夜夜、青山不老、日月如梭、稍纵即逝、贵阴贱璧、年复一年、弹指之间、光阴似箭、斗转星移、光阴荏苒、白驹过隙、呼吸之间、随时随地、千秋万代、立谈之间、尺壁寸阴、窗间过马、转眼之间、瞬息之间、一日三秋、昙花一现、日积月累、久而久之、喘息未定、咄嗟之间、天长地久。
- 频次：每天，每年，每月，每小时，每分钟。
- 时间段：几天后，几个月后

事件1和事件2都有相对时间的指向。

{事件1：人被狂犬病动物咬伤，事件2：人死亡，条件：[时间间隔：14天，人没打狂犬病]，充分性：1}

{事件1：人被狂犬病动物咬伤，事件2：人死亡，条件：[时间间隔：14天]，充分性：0.5}

{事件1：人被狂犬病动物咬伤，事件2：人死亡，条件：[时间间隔：None，人没打狂犬病]，充分性：？}#缺乏时间条件。

**时间处理流程**：

<img src="C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20210111144925145.png" align="middle" width="600">

**时间转换模块：**将意识流中的时间转换成标准化可处理的时间。

**时间处理的假设：**

1. - [ ] 假设任何具体事件都有其绝对时间，绝对时间包括（语境时间）。

2. - [ ] 假设任何知识（规律）是具有相对时间的。
3. - [ ] 规律的时间和绝对时间怎么区别？

     意味着一个时间向下的时间规律都是满足的。向上找匹配的背景，向下全部满足。
     
     

[**时间向量的转换**](D:\思维工程的疑问\认知系统\伪代码\time_dict.csv)

|  时间  |      时间向量       |
| :----: | :-----------------: |
|  清晨  |  * * 4-6 * * * * *  |
|  早上  |  * * 6-9 * * * * *  |
|  上午  | * * 9-11 * * * * *  |
|  中午  | * * 11-13 * * * * * |
|  下午  | * * 13-18 * * * * * |
|  晚上  | * * 18-23 * * * * * |
|  半夜  | * * 23-4 * * * * *  |
| 工作日 |  * * * * * 2-6 * *  |

​		当对所有事件的时间进行处理后，就要对两个事件的时间进行计算了。对于规律的频次信息,其时间描述会向下一级补充,比如"peter每年都会去旅游", 其时间描述为"* * * * 0-365 * * * "，表示这是个年规律，什么时候发生不确定。同理， "peter每天都会刷牙"，其时间描述为 "* * 0-24 * * * * * "。但是其时间规律中出现了两个级别的词，如"每天7点" "每周三"等，就表示这是一个较为具体的时间规律，则不用向下兼容了，也表示规律。“peter2018 年每周三都会去健身”，存在其向上的时间级别，就只需要获得最小时间单位。“peter2018年每周都会去健身”，没出现当前级别的更细值时，也向下兼容。

​		总的来说就是，那种“每天，每年，每周，每小时，每分钟，每秒”等具体的时间描述时都向下级补全。“每周三，每天7点，每年 1月等，不往下补全”。频次规律一般不发生冲突。冲突事件一般发生在较为精准定位的位格上，比如“每周三5点开车”和“每周三5点健身”时冲突。对于两个事件是否冲突，就采用询问的方式来获得更细的时间。持续时间等等，来判断其相斥性。		

| 序号 |             事件             |       时间描述       |
| :--: | :--------------------------: | :------------------: |
|  1   |     peter每年都会去旅游      | * * * * 0-365 * * *  |
|  2   |     peter每周三都会健身      |   * * * * * * 3 *    |
|  3   |     peter每周三都会开车      |   * * * * * * 3 *    |
|  4   |     peter每天早上7点起床     |   * * 7 * * * * *    |
|  5   |      peter每天都会刷牙       |  * * 0-24 * * * * *  |
|  6   | peter2018 年每周三都会去健身 |  * * * * * 2018 3 *  |
|  7   |  peter2018年每周都会去健身   | * * * * * 2018 1-7 * |



如下图的甘特图所示，既有瞬时发生事件（这里的最小单位是”天“），也有持续发生的事件。

![image-20210115132041120](C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20210115132041120.png)

<font color=red>**时间推理的计算问题暂定**</font>



#### 空间规律（待定）

​		空间规律也是描述一个事件是否发生的规则之一。

​		通常在空间节点上，事件是存在冲突性质的。比如一个人10点中在杭州开会，那么意味着这个时间他一定不会同时出现在北京。那么如果问11点他是否在北京呢？根据常识的判断，开会点到机场，飞起的起飞到降落等等，都说明这个不太可能。但是如果问下午他在北京么？同样根据常识判断，从10点出发，经过一系列手段，如果一切顺利，可能最快需要4个小时，那么就还有可能在北京。如果在这一系列手段中某个环节失效了，比如机票卖完了，都意味着下午他不可能在北京。或者即使他通过最优的方法到了北京，但是时间超了，也意味着他不可能在下午到北京。因此，就当前的状态，对于他是否在北京的理想可能性就已经确定好了。当然，我们可以采用目标分解演绎这个过程，通过最优演绎的结果来判断这个结果是否可信。



#### 事件集合运算

​		不可避免的，随着事件数量的增加，就需要对繁多事件类型进行总结和归纳，还包括事件类型的筛选。我们需要找到与一个事件相关或不相关的其他事件。

- 包含：本质上就是高充分性，意味着一个事件A发生，事件B也必然发生。
- 相等：本质上就是充要性，意味着两个事件任何一个发生，都意味着另一个事件也发生。
- 互斥：本质上就是一个事件的否事件，而否事件也存在充要事件，那么事件A与其否事件A‘，以及否事件的充要事件都与事件A互斥。

**事件集合运算**（用处不大）

- 并集运算：
- 交集运算：

​	

#### 询问（待定）

​		利用被咨询者的知识，结合对话者的语境信息，判断事件是否发生。如果得到否定的答案，如果对话者的直接感知不可及的，会尝试用因果层的知识转移好奇点到对话者感知可及的事件上。如果事件中包含了某类元素是对话者不熟悉的，会用一个对话者熟悉的母类替换。总的来说，就是针对**信息缺失、无法理解、推知不可得**的情况都会采用询问的方式来保证推理和对话的进行。



### 知识的获取

- 继承人类已有的方法
- 因为好奇点而进行询问或搜索
- 阅读书籍和文献

##### 信息的获取

​		有一件事是非常值得思考的，就是信息的缺失，要想计算具有一定的完备性，就要求数据具有很强的完备性。这就对AI提出了需求，能主动得搜索知识，阅读知识，理解知识，筛选知识，整理知识，总结知识，输出知识。



#### 好奇点

好奇点的几个来源：

1、先天定义的好奇形成反射。比如未知的词汇。

2、来自用户的询问。如果没有回答上来，就会成为好奇点。

3、判断一个事件是否发生时，通过因果链条把好奇点从目标事件转移到后延的表象事件或上游的原因事件。

4、目标分解驱动好奇点生成。个体对一个事件的发生或不发生有动机，如何使事件发生或不发生就是认知目标。

事件发生与不发生由背后因果链条所决定，从而会干预因果链条，让因果链条上的其他事件发生或不发生的，就能影响到目标事件的发生与不发生。这就是时间目标的转移。

会产生两类好奇点：

- 如何促成、维持、终止、阻止一个事件的时间目标的好奇。
- 对用以转移事件目标的因果类型的知识的好奇。

5、好奇心模型生成的好奇点。确认那类知识的重要程度高。



<font color=red>**要想对认知模型有更好的认识，需要对其他模块也有很好的认识。**</font>

 



### Chapter3 意味树

覆盖“推知过程的”的知识，**因果、时序、伴随、定义、意味**。



​		因果事件都通过反应触发来实现，特别是意味层的知识。Why?反应模式的触发模板可以是一个触发，多个条件的形式。什么意思呢？

这样的案例是很多的。

> 案例1：人得知亲人生病了，没有担忧，这个人是冷漠的。
>
> 案例2：人得知亲人生病了，非常担忧，这个人是温暖的。
>

​		上面的两个案例，是一个对立面，这个是可以根据一个数值的计算来判断这个是冷漠的还是温暖的，因为这两个形容词是存在共性的， 描述的是人同一个方面的情感，因此是可以用一个值来维护的。整句话可以认为是{前提事件A，前提事件B，结果事件C}



> IDs1：人得知亲人生病，人玩游戏，这个人不担心亲人。
>
> IDs2：人得知亲人生病，人睡觉，这个人不但心亲人。
>
> IDs3：人得知亲人生病，这个人不但心亲人，这个人是冷漠的。
>
> 案例1（间接）：人得知亲人生病，人玩游戏，（推知）这个人不但心亲人，（推知）这个人是冷漠的。
>
> 案例2（直接）：人得知亲人生病，这个人不担心亲人，（推知）这个人是冷漠的。
>



| ID   | 触发           | 条件             | 意味             |
| ---- | :--------------: | :----------------: | :----------------: |
| IDs1 | 人得知亲人生病 | 人玩游戏         | 这个人不担心亲人 |
| IDs2 | 人得知亲人生病 | 人睡觉           | 这个人不担心亲人 |
| IDs3 | 人得知亲人生病 | 这个人不但心亲人 | 这个人是冷漠的   |

​		当意识流中出现“人得知亲人生病”这个事件的时候，这个事件作为触发模板，F搜索()到相应的知识。这些知识有很多的条件，包括“人玩游戏”，“人睡觉”，“这个人不担心亲人”。



有两根质地不均匀的绳子，烧完都需要1个小时，怎么确定45分钟呢？

答：自己建立可以用的假设，第一，分别从两端点燃，那么绳子是可以烧半个小时的吗？所以解决办法是，一条绳子从两端一起烧，一条绳子从一端开始烧，当两端烧的绳子烧完后，点燃烧一端的那个绳子的另一端。



图中黄色表示**触发事件**，绿色表示**待触发条件**，灰色表示**已处理事件**。![image-20201223150443662](C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20201223150443662.png)

规则1：当从意识流中捕获一个触发事件，就仅从意识流中去寻找这个事件未处理的条件事件，实际上就是搜索这个触发事件后的事件。

规则2：触发事件不相干，且存在先后顺序。？？？？

规则3：由于两个事件可能互为触发事件和条件事件，而导致的推知事件可能不同。因此，要限定触发事件和条件事件的出现顺序，先出现的事件为触发事件，后出现的事件为条件事件。而当其中的一个条件事件为其他事件的触发事件时，也仅从后面的事件中去寻找条件事件。这意味着如果出现{触发：事件1，条件：事件2，推知：事件3}，{触发：事件2，条件：事件1，推知：事件4}时，会要求事件1在事件2后再出现，来保证推理逻辑的合理性。而很多情况是，第一个事件1和第二个事件1，表达的意思是一致的，但是其时间戳是不一样的，所以就可以认为两个事件1不是同一个事件。比如：{人玩游戏，人得知亲人生病，人玩游戏，人不担心亲人}，在这个事件序列中，两个人玩游戏的时间状态是不同的。因此在使用{人得知亲人生病}时，不会找到前面这个{人玩游戏}事件来推知事件。

规则4：只有当一个信息队列不再增加新的推知事件后，再开始进行信息整合工作。

规则5：推知关系是建立在属性层的，因此推知关系的建立是相对严格的。

规则6：待确认条件列表，应该是一个二维列表[[],[事件1],[事件2，事件3]]，这意味着对于一个触发事件，其待确认条件可以是一条，可以是多条，也可以直接推知，比如，{苹果很红，苹果很好吃}。对于不同的触发条件，需要建立一个新的二维列表来保存其确认条件。

<img src="C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20201225105633546.png" width="600" title="触发事件的处理流程">



#### 基于RNN原理的推理

​		RNN网络是一种循环神经网络模型，在文本处理的领域有着非常显著的作用， 主要是处理那些序列问题。即使是在Transform盛行的当下，也能发现这种序列处理的逻辑。因此，在意味树的推理或构建过程中，我们也去参考这些。参考RNN网络，我将触发反应模板核和意识流信息进行向量化处理。如下所示：

触发事件的反应模板：

| 序号 | 触发事件 | 条件事件列表           |
| ---- | -------- | ---------------------- |
| 1    | ID~A~    | []                     |
| 2    | ID~A~    | [ID~A4~]               |
| 3    | ID~A~    | [ID~A1~]               |
| 4    | ID~A~    | [ID~A1~,ID~A2~]        |
| 5    | ID~A~    | [ID~A1~,ID~A2~,ID~A3~] |

转换成向量，这个向量是由触发事件的条件事件构成。

| ID~A1~ | ID~A2~ | ID~A3~ | ID~A4~ |
| ------ | ------ | ------ | ------ |
| 0      | 0      | 0      | 0      |
| 0      | 0      | 0      | 1      |
| 1      | 0      | 0      | 0      |
| 1      | 1      | 0      | 0      |
| 1      | 1      | 1      | 0      |

```python
#IDA_inf_list=[[0, 0, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0], [1, 1, 0, 0], [1, 1, 1, 0]]
IDA_inf_list=[[],[IDA4],[IDA1],[IDA1,IDA2],[IDA1,IDA2,IDA3]]
IDB_inf_list=[[],[IDB1],[IDB2,IDB3],[IDB4,IDB5]]
C_list=[IDA,IDB]
#表示的是将触发事件反应模式转换成一个向量。至于向量的维度，是根据意识流中的信息数量决定的。
id_from_S=[id1,id2,id3,id4,id5,……,idn] #意识流中的信息
#根据id_from_S中的信息，并根据触发列表对应的反应模式列表。将IDA_inf_list转换成one_hot编码。
IDA_inf=[[0,0,0,1,0,1,0...0],[0,0,0,1,0,0,0...0],[1,0,0,1,0,0,1,...0],...[1,1,1,0,0,0,0,...0]]
IDB_inf=[[0,0,0,0,0,0,1...1],[0,1,1,0,0,0,0...0],[1,0,0,0,1,0,1,...0],...[0,1,0,0,0,0,0,...1]]
#这个向量与id_from_S形成的向量是可以发生计算的，计算的过程待定。
list_for_c=IDA_inf*id_from_S #获得被激活的事件反应模式，这些反应模式中的信息是需要被抽取出来发生计算的。
```

再而，参考RNN网络构建阅读的过程信息处理的流程，如下所示：

RNN:



<img src="https://upload-images.jianshu.io/upload_images/8762099-8e46a3c5566b0d07.png?imageMogr2/auto-orient/strip|imageView2/2/w/600" width="600" title="RNN">

LSTM:

<img src="https://upload-images.jianshu.io/upload_images/6592751-dbad8a300a2adc52.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200" width="650" title="LSTM">

意识流中信息的处理流程：

方案一：

<img src="C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20210204164651544.png" height="500" title="触发反应模式模块">

![方案一](C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20210204172304527.png)

​		在图中，$S_t$表示t时刻的意识流信息，$h_t$表示经过触发反应模块处理完成后的意味层信息。意识流信息，进入网络会先进行关注度的计算，超出阈值事件作为触发事件，并在知识库中搜索触发事件对应的触发模板，与意识流信息进行相互作用后，输出为根据意识流信息触发的反应模式。然后激活的反应模式会输出意味层信息，意味层信息可以单独输出，也可以和原来的意识流信息合并，得到需要进一步处理的意识流的信息。新得到的意识流信息，还需要进行概率计算（即事件的合并）。经过处理后，还要经过关注度的处理，才能进入下一步的运算，如此满足循环需求。

**1 如果意识流有新的信息进来怎么办？**

答：和这个处理流程要求的一样，意识流信息进入触发反应模块都是需要进行关注度计算的，这意味着我可以在任意一个触发反应模块之后对意识流信息进行处理。即保留了原文的信息，又能根据上文推知的信息对新出现下文进行处理。而这中，触发反应模板是可以人为学习获得。难点全部都集中到关注度的计算上去了。总的来说，计算上是完备。

**2 什么时候停止循环计算呢？**

答：这个没有完全的限定，这取决于意识流信息什么时候消除，以及是否需要激活意味树反应。文章的阅读结束，不能决定推知结束了，也许还有基于对话的交流呢？所以这都取决于对意识流本身的处理。

**3 怎么解决触发事件和条件事件出现顺序的问题**？

答：首先意识流中的信息是默认按照时间顺序进入的，当然事件本身是具有事件时间戳的，如果没有时间戳，会生产好奇点，从上下文中去寻找，这主要是时间模块需要解决的问题，我们默认都有时间戳。如果触发模板对事件出现顺序有要求，那么会对触发事件与条件事件做个时间判断，比如，”我在玩游戏，我得知亲人的负面信息“和”我得知亲人的负面信息，我在玩游戏“其触发的反应模式是不同的。这里，我们通常会定位触发事件（”我得知亲人的负面信息“）出现的位置，而只从其后的事件去寻找条件事件。

**4 怎么解决多触发问题，比如激活的触发模板，其很多条件事件被激活了？**

答：意识流的信息，有个特点，事件可能会重复出现，在不同的位置说明不同的问题。因此，对于一个触发模板，对整个意识流信息进行处理的过程中，会激活多个条件事件。那么哪一些条件事件会被激活和运算获得意味层信息呢？比如，{”我得知亲人的负面信息，我在玩游戏“意味着”我很冷漠“}，在其后出现，”从医院回来，我休息了一会儿，我准备玩会游戏“。是否还是会说明”我很冷漠“？答案是的。但是，也出现了新的事件，”从医院回来“，意味着”我不冷漠“。两个评价会综合评价一个人。那么如果，”我玩游戏“，出现在更遥远的时间呢？比如，”一年后，我在家玩游戏，亲人坐在我旁边和我开玩笑“。这个时候，上文的触发事件与条件事件按道理就没什么关系了。那么这样的问题怎么解决呢？这应该是关注度维护模块需要解决的事情了？一个触发事件，势必只会对某一些方面事件，或某一个时间段事件产生好奇，就是只会关注某几个域的事件。这个域怎么确定呢？

解决方案一：一个方法是让关注度模块来实现。在阅读过程中，就会找那些相关性的事件，尝试的建立联系。

解决方案二：信息的收集，只有那些需要注意的事件，才会进入计算。首先会进行一次聚类操作，聚类的方法是待定，聚类的结果就是从

意识流中找到与触发事件相关的事件。

还有对于多触发事件，也优先触发多条件的触发事件。

**5 什么是待判断条件？**

答：就是那些触发模板有的条件事件，但是意识流中没有，是隐藏的条件事件，需要挖掘的事件。隐藏的事件一部分需要同义转换，一部分需要后续的推知才能获得，还有一部分是主动的建立假设。主动建立假设的情况是比较复杂的。什么时候会主动建立假设？ 

 **6 注意力机制的计算问题？**

答：

**7 尝试借助self-Attention机制计算？**

答：



> 已知：
>
> ##### 简单场景1：
>
> 从意识流中抽取的信息队列为：{a,b,e,f}
>
> 事件时间顺序：$t_a<t_b<t_e<t_f$
>
> IDs：a+b>c, a+c>d,e+f>g,
>
> 经过意味计算为{a,b,e,f,c,g,d}
>
> ##### 中等场景2：
>
> 从意识流中抽取的信息队列为：{a,b,e,f}
>
> 事件时间顺序：$t_a<t_b<t_e<t_f$
>
> IDs：a+b>c, a+c>d, e+f>g, **c+f>h**
>
> 经过意味计算为{a,b,e,f,c,g,d}
>
> 注意：在这里，生成的c可能是f的触发事件，但在实际情况中，这样的现象是很少见的，因此认为，c+f>h这条知识是不被触发的。
>



#### 推理的结束

​		对于一个事件的推理什么时候结束是一个值得思考的问题。因为信息的整合以及概率和程度的计算是在一个触发事件结束的时候才启动的。当新的信息进来，



#### 不同事件规律下的测试

```
2020.12.26:考察了事件规律和对象规律发现，对于“推知过程”，其“触发事件”可以是“事件规律”，也可以是“对象规律”，因此我们将“触发事件”更改为“触发条件”比较合适。

以下梳理不同事件规律下意味推理案例：

A：对象间的从属关系：

IDs{“大部分鼠类都是杂食动物”，“大部分老鼠喜欢吃谷物”}。实际上在一些特殊场景中，事件1就不会输入到意识流当中，而更可能是从知识中搜索获得而放到意识流中去的。这其实说明了一个问题，就是通常进入意识流信息是一些感知信息，而其他信息（特别是知识库中的信息）是根据子系统的需求，或者说响应（好奇点），才输入到意识流当中去的，而进一步的参与到推知运算中，而且主要是做为待判断条件。

B：对象属性型：

IDs{“这个葡萄很酸”，“这个葡萄不好吃”}

IDs{“这个葡萄很酸”，“维C含量很高”}

IDs{“这个葡萄不酸”，“这个葡萄可能比较好吃”}

这个是一个程度的推知案例，根据对象属性的不同程度会推知出不同的结果。

C:事件类规律

IDs{"小明经常熬夜"，“小明身体可能不健康”}

IDs{“夏天，大多数人穿短袖”，None}，这说明有些事件只有在存在条件事件时才会触发反应。

一个事件类型很难推知一个结果，但是一个对象属性，比较好推知的。
```

结论：暂时没得到什么结果。



### 意味树中的数值计算

<font color=red>**贝叶斯推断（Message Passage）**</font>：是一种推理统计的方法。在有更多证据及信息时，更新特定假设的概率。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy81NURpYjFYVTB3cHEzN2lidmVhcUJHRDluUFlHVnNadm01YUFxTGpGdTd4enNsbUdmWU5Fa2lidXRhalR3d2ZPZVVXdTMzdElucUY0b3ppYjhGdmliMFZEM09RLzY0MA?x-oss-process=image/format,png)

​		贝叶斯推断可以使用在计算条件概率上。比如P(猫咪挨踢|爸爸上班挨批)、P(猫咪没事|爸爸上班挨批)等等。F和C刚开始没有建立联系，但是在这样的路线构建起来后，就可以不借助中间事件的概率计算了。 这就是条件概率的计算问题。

#### 贝叶斯推断

新的信息进来，要经过3个步骤的操作。

1. 对新的信息可信度的判断。（这已经属于高级功能了）
2. 将信息放到和它相关信息中去。（信息的聚合操作）
3. 新信息和旧信息怎么相互作用。
4. 计算的结果怎么输出。

**形成的聚类图认为是<font color=red>有向无环图</font>。**

​		可以借鉴一个思路，让机器自己思考，然后达到一个稳态。这样的循环机制最终都会回归到神经网络上来，近似梯度回归。对于个体而言，获得的是离散的数据，因此人的思路是没有非常明显的梯度计算过程的。当然不排除未来的人，会尝试使用这样的思想来思考，这样会让思维的准确性有所提高。但是对于生物的人，其并不擅长大数据的计算，人更多的是擅长抽象的计算和逻辑的计算。因此，我们对非生物体的机器而言，要对其提出不同的要求。

#### 数值类型和作用

对于事件类型到底具有哪些数值是有待考究的。

离散事件具有待发生的可能性。

带程度的事件会有置信度和程度两个维度的信息。

- 事件类型需要有时间戳，用于信息队列中信息的排序。

- 事件类的程度，用于描述事件中主体的属性程度，对于离散事件默认数值为1。比如苹果很红，则生成，[0.7-0.8]之间的随机数，至于程度区间，人为划分。又比如，人玩游戏，程度值就为1，因为对其他事件不产生影响。？？？
- 事件发生的概率，

#### 信息的整合

​		在一次意味推理过后，意味推理层完成了其作用，但信息整合模块还需要考究一些事情。比如什么样的事件需要整合，正如之前案例中出现的，人玩游戏事件，是具有不同时间戳的，因此没办法进行信息整合工作。



### 意味树的统辖搜索

​		意味树的统辖搜索是个比较复杂的问题，因为一个实体可以具有很多的属性，或者归属的类别。对于不同的属性和类别会有很多可能，如何选择正确的属性和类别，决定了当前实体能匹配到怎么样的知识。如何防止其他的推知的结果呢？也许其他的干扰项的影响是比较小的呢？如何让哪些影响小的事件不加入计算呢？Of，course，通过关注度阈值来维护。那么怎么来提高或降低关注度呢？认为和目标对象（实体或事件）直接相关的对象的关注度的值提高到一个较高的水平，由此再去搜索其下下游的事件或目标的关注的值，但是下游关注度的值是根据相关事件发生衰减的。只有当事件作为新的目标对象的时候，才会将当前事件的关注度提高。**所以关注度的作用本质上也还是，作为意识流信息流量控制的阀门，起到了信息过滤和筛选的作用。**这样就能有效的防止信息过溢。

​		统辖搜索是怎么实现的，参考之前的原理，对其进一步优化。



### 意味树的构建

蓝色和紫色表示触发事件，黄色表示条件事件，绿色表示意味事件。

触发列表：[ID~A~,ID~B~]，意识流信息：[ID~A~,ID~B~,ID~C~,ID~D~,ID~E~,ID~F~,……]











### <font color=red>待解决的问题：</font>

1、关注度、置信度，发生概率，程度，发生次数的计算问题。

2、意识流中信息如何选择触发条件。频次？关注度？先后顺序？

- [x] 3、触发事件的开始和结束？决定了当前触发是否还要处理后续产生的信息。

- [x] 4、如何界定当前事件已经被处理了？也就是说当前事件不进入重复的触发列表。

5、从具体事件到知识？增加知识的统辖搜索后，计算量大大的增加了。

6、输入到意识流的信息，通过什么办法进行整合？推知事件出现了重复，需要进行信息的整合。

- 有点像神经网络的线性全连接层，一个是对当前的进行输出，然后再将新的信息再输入触发器中再计算。

7、重算知识系数怎么实现？

8、统辖搜索的实现。

9、推理模板建立的标准。推理模板是具有较强的约束关系的。

10、对于意味层模板建立的一些限制，建立在属性层。

IDs1:人得知亲人生病，人玩游戏，人不担心亲人。（创造关系）

IDs2:人玩游戏，人得知亲人生病，人停止玩游戏。（阻止关系）

IDs3:人玩游戏，人得知亲人生病，人感觉悲伤。（创造关系）

IDs4:人玩游戏，人得知亲人生病，人担心亲人。（创造关系）

IDs5:人得知亲人生病，人不担心亲人，人是冷漠的。（推知关系）

推知关系是建立在属性层的吧？

<font color=red>11、要对不同的事件类规律进行整理，发现并找到在数值计算上的规律</font>。包括**{事件类相互导致，事件类时长，事件类数量，事件频次}**。

答：

12、为了增加推理的泛化性能，还需要有参数的维护机制，就是参考神经网络梯度更新的方法，利用验证数据集和训练数据集提高参数的准确定性。

13、认知还有一个作用，对知识的正确性进行判断，并对原有错误的知识的修正。

14、两个事件之间的充分性和必要性是怎么获得的？

​		根据好奇点或是语义成分，判定其是一个无条件事件，还是有条件事件。对于无条件事件，尝试挖绝隐藏条件。

15、



## Chapter4 统计的认知---突破知识的边界

统计认知的作用：形成事件类规律。

对于同类的事件，或多个相似的事件，总能总结出一定的规律。

对于错误的概率，并不影响其最终的结果。

那么对于多个事件，计算机是怎么对相似的事件进行计算的呢？

相似度的计算。

- 行为上：同一动作
- 属性上：同一特征
- 对象上：同一类
- 事件：同一类型的事。

相似度计算，借助图的计算。



#### 突破知识的边界

**因果链条的桥接**：当我们发现两个事件之间不完美的相关性，我们试图找到这个相关性背后的因果链条，从而实现精准的对事件的干预。

  当一个好奇点无法被阅读、询问获得。

发现新知识的两种方法。

- 从表象事件出发。

  从许多样本的事件的序列中发现因果相关性的规律。`比如心脏不好的人有哪些相似的习惯，从而知晓哪些生活习惯导致的结果。`->不具有科学验证性。但是仅通过样本的统计的方式获得的相关性是较弱的。

  具体的样本-->发现事件的发生规律----**因果链条的桥接**--->对背后的机制形成猜想--->验证猜想。

  考察猜想因果链条上的事件点是否发生（表象层）。

- 从更抽象的知识层出发。

  

  M语言只考虑浅层的因果知识，而不考虑深层的知识。这是最大的弊端。

  判断事件是否发生就是分类任务吧？

  M语言根据一个样本生成猜想。

#### 因果知识的不完美性

我们通常观察到的是宏观层的规律，而不去更深入的思考微观的复杂的因果知识，而这种知识通常是不完美的。

实际上我们拥有大量的知识，但绝大部分都只是在描述因果相关性，不是因果法则。

虽然我们现有的因果规律并不完美，但始终可以在进一步的探索中变得完美。

因为所有我们认为的真理或是法则实际上还是“猜想”，这些猜想还是需要进入**”实践反馈环“**来帮助因果规律的验证。

还有细致的因果链条需要基于样本的观察。

#### 因果相关性自发的建立

我们对因果关系的认知，起点在于感知，感知事件的发生与不发生，状态的存在与不存在。

统计认知的两种基础模式：

- 自发的抽象

  - 时间轴上在短时间内连续出现的**关注**事件。
  - 针对特定对象的连续出现的**关注**事件。

- 从记忆中寻找

  好奇点驱动，目标比较明确，比如事件类会由什么导致，可能会导致什么结果。

  从个别具体事件IDA在事件轴上寻找关注的其他具体事件IDB，再找到具体事件的母类事件类，构成猜想，再进行初步认证。

  验证充分性，IDB的子类找到IDA伴随的子类的比例。

  验证必要性，IDA的子类找到IDB伴随的子类的比例。


#### 正规的样本采集和论证

  对于上面验证获得的数据是不严格的，由于数据的不充分和不完整，对于事件间的充分性和必要性的定量都是不准确的。一些极端数据的缺失，会导致无法发现规律。因此，可以通过单独的喂数据来帮助猜想的验证。  

#### 发现更细致的规律

多条条件的目标事件关系是个问题？？？？？



事件类和具体事件的结构是一样的吗？

事件类规律：

1. 事件类相互导致（事件1=事件IDA,导致事件类=IDB，充分性=p，必要性=q）
   1. 较弱相似事件类型时序关系
   2. 较弱相似事件类型伴生关系
2. 事件类时长（事件类=，一般时长=，）；（事件类=，时长=，样本比例=）
3. 事件类数量规律（事件类=，指向对象一般数量=，）；（事件类=，指向对象数量=，样本比例=）
4. 事件频规律（事件类=，一般规律=）（事件类=，频率=，样本比例=）
5. 所有规律都可以带条件。条件规律（条件=，规律=）“夏天大部分葡萄都是酸的”



## chapter4 辅助知识

### 知识推理

知识推理有两种不同的类型。

#### 基于演绎的推理

​		自上而下。在给定一个或多个前提情况下，推断出一个必然成立的结论。肯定前件假言推理、否定后件假言推理以及三段论。

> 假言命题：“如果今天是星期二（前件）。那么小明会去上班（后件）”

- 肯定前件假言推理：“今天星期二。” ——> "小明会去上班。"

- 否定后件假言推理：“小明不会去上班。”——>“今天不是星期二。”

- 三段论：“如果小明生病了，那么小明会缺席。”，“如果小明缺席了，他将错过课堂讨论。”——>"如果小明生病了，他将错过课堂讨论。"

#### 基于归纳的推理

​		自下而上。基于已有的部分观察得出一般结论的过程。

- 归纳泛化（Inductive Generalization）：基于个体的观察而得出可能适用于整体的结论。

- 统计推理（Statistical Syllogism）：将整体的统计结论应用于个体。“就读于某高中的同学80%能上大学，小明就读于这所高中。”——>“小明有90%的机会能上大学。”
- 溯因推理：在给定一个或多个已有观察事实O（Observation）并根据已有的知识T（Theory）推断出对已有观察最简单且最有可能的解释过程。“下雨了地一定会湿（T）”，“观察到马路是湿的（ O）”——>“很大概率是因为下雨了（E）” 。注：前提和结论没有必然的联系。
- 类别推理：只基于对一个事物的观察而进行的对另一个事物的归纳推理。寻找两者之间可以类比的信息，将已知事物上的结论迁移到新的事物上的过程。“小明和小红是同龄人，他们都喜欢歌手A和歌手B，且小明还喜欢歌手C，那么推理出小红也喜欢歌手C”但是这样的错误很高，叫“类比不当”。
- 不确定推理：根据不确定的观察信息以及不确定性的知识进行推理的不确定性推理。也分为精确推理和模糊推理。
- 自然语言推理：判断两个给定句子的蕴涵关系。给定一个前提，一个假设结论。判断给定前提句子的情况下是否可以推理出假设结论的句子。”冲突“、”蕴含“、”中立“。



在建立实体、关系推理的上，需要建立一个关系集合的推理，**公理集合**。比如has_son和has_child，has_mother和ismother，等关系的推理网络。



### 推理机

 主要见于专家系统。专家系统是早期人工智能的一个重要分支，它可以看作是一类具有专门知识和经验的计算机智能程序系统，一般采用人工智能中的知识表示和知识推理技术来模拟通常由领域专家才能的解决的复杂问题。

专家系统=知识库+推理机。

计算机领域高质量期刊会议：CVPR、ECCV、ICCV、AAAI、NIPS、ICLR、ICML

Talk is cheap.Show me the code。

#### 知识的分类

- **逻辑性知识，形象性知识**

逻辑性知识，是反映人类逻辑思维过程的知识，一般具有因果关系或难以精确描述的特点，	是人类的经验性知识和直觉感受。

形象性知识，通过事物的形象建立起来的知识。如，什么是牛？

- **显性知识，隐性知识**

  显性知识，文字、语言、图像、声音等。

  隐性知识，长期积累的知识，不易用显性知识表达的知识。如每个人都有不同的审美。

- **确定性知识和不确定性知识**

  确定性知识，其逻辑值为真或假的知识，是精确性知识。

  非确定性知识，不确定，不安全，模糊性知识。

#### 知识的表示

我们希望知识的表示是有不同的形式的，但对其有相应的要求，我们考虑以下几个因素。

- 能否充分表示相关领域的知识。
- 是否有利于对知识的利用。
- 是否便于知识的组织和管理。
- 是否便于理解和实现。



#### 三段论推理

​		三段论推理是演绎推理中的一种简单推理判断。他包含：一个包含大项的命题**（大前提）**，一个包含小项和中项的命题**（小前提）**以及一个包含小项和大项的命题**（结论）**。是数学证明、办案、科学研究等的思维方法。

大前提：一般性的原则

小前提：附属于一般性的原则

结论：符合一般性原则的特殊化陈述



#### 假言推理

<img src="C:\Users\莫品军\AppData\Roaming\Typora\typora-user-images\image-20210129150531913.png" height="450">

##### 充分条件假言推理

根据充分条件假言命题的逻辑性质的推理。

充分条件假言推理有两条规则：

规则1：肯定前件，就要肯定后件；否定前件，不能否定后件。

规则2：肯定后件，不能肯定前件；否定后件，就要否定前件。

| 前件 |  后件  |
| :--: | :----: |
| 肯定 |  肯定  |
| 否定 | 不否定 |

| 后件 |  前件  |
| :--: | :----: |
| 肯定 | 不肯定 |
| 否定 |  否定  |

##### 必要条件假言推理

根据必要条件假言命题的逻辑性质进行的推理。

规则1：否定前件，就要否定后件；肯定前件，不能肯定后件。

规则2：肯定后件，就要肯定前件；否定后件，不能否定前件。

| 前件 |  后件  |
| :--: | :----: |
| 否定 |  否定  |
| 肯定 | 不肯定 |

| 后件 |  前件  |
| :--: | :----: |
| 肯定 |  肯定  |
| 否定 | 不否定 |

##### 充分必要条件假言推理

充分必要条件假言推理是根据充分必要条件假言命题的逻辑性质进行的推理。

规则1：肯定前件，就要肯定后件；肯定后件，就要肯定前件。

规则2：否定前件，就要否定后件；否定后件，就要否定前件。

| 前件 | 后件 |
| :--: | :--: |
| 肯定 | 肯定 |
| 否定 | 否定 |

| 后件 | 前件 |
| :--: | :--: |
| 肯定 | 肯定 |
| 否定 | 否定 |



#### 演绎假设推断

基本方法：先假设目标事件成立，从其后延的结果事件出发，逐一判断其高必要的结果事件是否存在或成立，只有那些高必要的条件都成立，我们才认为假设成立，否则此假设不成立，需要建立新的假设。

这里需要判断目标事件本身，假设的方向，结果事件和目标事件的关系。

##### 判断目标事件为真的情况

- 如果目标事件是一些事件的充分不必要条件，那么结果事件大概率发生。

- 如果目标事件是一些事件的必要不充分条件，那么结果事件不一定发生。

- 如果目标事件是一些事件的充分和必要条件，那么结果事件大概率发生。

总的来说就是，假设目标事件为真时，要从目标事件的演绎结果判断，就要从**目标事件为高充分性**的相关事件的结果事件寻找，而对于结果事件的必要性没有要求。

**判断目标事件为假的情况**

- 如果目标事件是一些事件的充分不必要条件，那么结果事件不一定不发生。

- 如果目标事件是一些事件的必要不充分条件，那么结果事件大概率不发生。

- 如果目标事件是一些事件的充分和必要条件，那么结果事件大概率不发生。

总的来说就是，假设目标事件为假时，要从目标事件的演绎结果判断，就要从目标事间的相关事件的**高必要结果事件**寻找，而对于目标事件的充分性没有要求。

> 注：这里都是让目标事件为**前件**的情况下做的判断。在两个事件的因果关系中，兼具有充分性和必要性，前件和后件可以相互转换，也就是只需要提取相应的信息即可。

目标事件为高充分性事件时，结果事件会很多，表示结果事件很大概率会发生。比如，我得了狂犬病→我很有可能死亡，我就很有可能出现怕水的症状。而没出现一个高充分目标事件得结果事件都会增加我得狂犬病得概率。

结果事件为高必要条件时，意味着所有高必要事件都不能存在，才能说明目标事件不成立。比如，我没有恐水的症状，我没有进行性瘫痪→我没有得狂犬病。```我没有死不能说明我没有得狂犬病，因此不是高必要条件。```



### 认知系统工程处理逻辑

#### 自然语言转换成M语言，并进行知识推理

状态的开始-维持（变化）-终止和转移，用一个状态转移变量实现。

##### 案例1：

> peter穿着红色衣服站在广场上，而广场上来了一只强壮的公牛，看到peter。

M语言如何转换成母类的意识？

```python
{{{{对象1：“peter”；link：“穿着”；对象2：{adj：”红色“；对象：”衣服“}}；link：”站在“；对象：”广场上“}；link：”而“；{{对象：“广场”；link：“来了”；对象：{“一只强壮的公牛”}}；link：“看到”；对象：”peter“}}
```

这个案例实际上想抽象出，牛看到穿红色衣服的peter，牛会攻击peter的输出。因果链条的输出。

本质是做事件的推断？这是一个输出内容的决策过程，选择在哪里收敛的问题。

疑问：

```python
#一种复杂的统辖结构，放在...下面，站在...上面
#这种关系是怎么搭建的？以及怎么提取的？
#模糊搜索怎么匹配？其评价标准？
```

#### 符号主义的编程思想？

​		摆脱机器学习或大数据的一些基本概念，来构建知识图谱，人为的创造多个决策树。而这就是未来符号主义的主要表达方式。但是由此而来会存在一个问题，决策树的建立强关联人的主观判断，如何判定哪棵决策树的特点呢？辅助一些数学统计上的认知。



##  Chapter5 其他

**早在1763年，议员约翰.威尔科斯就在其主办的《北不列颠人》上抨击国王和政府的选举制度。**



原先：

1   1.1（主语对象=ID1，对象类=议员）1.2（主语对象=ID1，名称=约翰）

2（主语对象=ID1，行为=主办，指向=ID2）

3   3.1（主语对象=ID2，名称=北不列颠人）3.2（主语对象=ID2，属类=杂志或报纸）

4（主语对象=ID1，抨击=，内容=ID3，表达载体=ID2）

5（主语对象=ID3，属类=选举制度）

6（主语对象=国王|政府，行为=确立，规则=ID3）

修改为：

1   1.1（主语对象=ID1，属类=议员）1.2（主语对象=ID1，名称=约翰）

2（主语对象=ID1，行为=主办，指向=ID2）

3   3.1（主语对象=ID2，名称=北不列颠人）3.2（主语对象=ID2，属类=杂志或报纸）

4（主语对象=ID1，抨击=，内容=ID3）

5  5.1（主语对象=ID3，属类=选举制度）5.2（主语对象=ID3，表达载体=ID2）

6（主语对象=国王|政府，行为=确立，规则=ID3）



**是不是会有利于抽象策略和逆转录？**

抽取了1，4，5.1，就可以转化成 “ 约翰议员抨击选举制度”

抽取1.1，4，5.1，就可以转化为“议员抨击选举制度”

抽取1.2，4，5.1，就可以转化为“约翰抨击选举制度”

如果只抽取4，因为位格中存在ID1和ID3，默认就要找ID1和ID3对应的属类。就获得“议员抨击选举制度”

以上其实说明将**原先**的4拆分成5，这样有利于抽象或逆转录策略。



**“君弱---臣强    --->   君杀臣，臣弑君”**

特别是“君弱，臣强”这样的通过**属性意向层**抽象出来的规律要等一下，因为推到这一步，

中间涉及很多模块，”**属性意向层**“的定义和获得不是很完备，甚至也需要情绪系统的介入。

还有**因果关系的桥接**等等，但这也不是简单的因果关系，这里的细节都还没考虑清楚。

基于现在的一些抽象方法，像“君杀臣，臣弑君”这样的规律是容易获得的，找到子类也相对容易。

但是带属性的规律就不好抽象，这和归纳“一只强壮的公牛看到穿红色衣服的爸爸攻击了爸爸”，不大一样吧。

Q：是否目前的认知的重点可以放到，通过因果关系，解决**“具体事件--意向--君弱”**的逻辑问题？？？

Q：是否需要重新考虑认知模块的一些工具（目标分解、是否发生等）在这方面的实现？



**属性意向层案例：**

eg1：

这个苹果很红。---> 这个苹果很好吃。

eg2：

晚饭很香。---> 晚饭很好吃。

eg3：

康熙年幼。---> 康熙很柔弱。

Q：这个案例是怎么推理的？

Q：如直接写意味层的模板，那推理时就一定要在意味层上推理吗？

eg4：

鳌拜走进康熙的书房，康熙正襟危坐。---->康熙很柔弱？

Q：康熙很柔弱应该不是直接推理出来的吧，推理的方向会有很多。



**因果逻辑层的分解**

**属性意向层的分解**



历史性的文章存在的问题，比如说谥号，朱棣的“后天弘道高明肇运圣武神功纯仁至孝**文**皇帝” 。

努尔哈赤的“承天广运圣德神功肇纪立极仁孝**武**皇帝”。

君弱臣强的案例：



#### 事件关系：

Q：在思考从意识流中捕获信息，涉及处理的模板，不能简单的用 {触发：，条件：，推知} 模板。

**IDs1:人得知亲人生病，人玩游戏，人不担心亲人。（创造关系）**

IDs2:人玩游戏，人得知亲人生病，人停止玩游戏。（阻止关系）

IDs3:人玩游戏，人得知亲人生病，人感觉悲伤。（创造关系）

IDs4:人玩游戏，人得知亲人生病，人担心亲人。（创造关系）

**IDs5:人得知亲人生病，人不担心亲人，人是冷漠的。（推知关系）**

推知关系是建立在属性层的吧？

创造阻止、维持等关系也能用推知模板来实现吗？

















